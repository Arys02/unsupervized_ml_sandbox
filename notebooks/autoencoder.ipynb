{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from config import MODELS_DIR"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tranform = transforms.ToTensor()",
   "id": "9a14851716409758",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=tranform, download=True)\n",
    "val_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=tranform, download=True)"
   ],
   "id": "d35ef4e6302fbfba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=1024, shuffle=True, num_workers=4)\n",
    "val_dl = torch.utils.data.DataLoader(val_dataset, batch_size=1024, shuffle=True, num_workers=4)"
   ],
   "id": "dda4c7f504d936f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size=28*28, hidden_size=None, z_dim=2):\n",
    "\n",
    "        super().__init__()\n",
    "        if hidden_size is None:\n",
    "            hidden_size = [128, 64, 8]\n",
    "\n",
    "        self.encoder = nn.ModuleList()\n",
    "        prev_size = input_size\n",
    "        for size in hidden_size:\n",
    "            self.encoder.append(nn.Linear(prev_size, size))\n",
    "            prev_size = size\n",
    "\n",
    "        self.encoder.append(nn.Linear(hidden_size[-1], z_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        for i in range(len(self.encoder) - 1):\n",
    "            x = torch.relu(self.encoder[i](x))\n",
    "        x = self.encoder[-1](x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "16b55cab4dd891c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size=28*28, hidden_size=None, z_dim=2):\n",
    "        super().__init__()\n",
    "        if hidden_size is None:\n",
    "            hidden_size = [128, 64, 8]\n",
    "\n",
    "        hidden_size.reverse()\n",
    "\n",
    "        self.decoder = nn.ModuleList()\n",
    "        prev_size = z_dim\n",
    "        for size in hidden_size:\n",
    "            self.decoder.append(nn.Linear(prev_size, size))\n",
    "            prev_size = size\n",
    "\n",
    "        self.decoder.append(nn.Linear(hidden_size[-1], input_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.decoder) - 1):\n",
    "            x = torch.relu(self.decoder[i](x))\n",
    "        x = torch.sigmoid(self.decoder[-1](x))\n",
    "        return x\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "2c81a511a2c900ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "id": "b2e563e9f9ebd52a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "enc = Encoder().to(device)\n",
    "dec = Decoder().to(device)\n"
   ],
   "id": "acf29324a7143e4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "enc_compiled = enc\n",
    "dec_compiled = dec"
   ],
   "id": "a1a20c937ecd2d22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "# optimizer_enc = torch.optim.Adam(enc.parameters())\n",
    "# optimizer_dec = torch.optim.Adam(dec.parameters())\n",
    "optimizer_enc = torch.optim.Adam(enc_compiled.parameters())\n",
    "optimizer_dec = torch.optim.Adam(dec_compiled.parameters())\n"
   ],
   "id": "94cb115cb32de4ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "train_loss = []\n",
    "num_epochs = 200\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    train_epoch_loss = 0\n",
    "\n",
    "    for imgs, _ in train_dl:\n",
    "        print(imgs.shape)\n",
    "        imgs = imgs.to(device)\n",
    "        imgs = imgs.flatten(1)\n",
    "        # latent = enc(imgs)\n",
    "        # output = dec(latent)\n",
    "        latent = enc_compiled(imgs)\n",
    "        output = dec_compiled(latent)\n",
    "\n",
    "        loss = loss_fn(output, imgs)\n",
    "\n",
    "        train_epoch_loss += loss.cpu().detach().numpy()\n",
    "\n",
    "        optimizer_enc.zero_grad()\n",
    "        optimizer_dec.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer_enc.step()\n",
    "        optimizer_dec.step()\n",
    "\n",
    "\n",
    "    train_loss.append(train_epoch_loss)\n",
    "\n",
    "\n"
   ],
   "id": "e33415d4c8453cfe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "torch.save(enc_compiled.state_dict(), 'enc.pth')\n",
    "torch.save(dec_compiled.state_dict(), 'dec.pth')"
   ],
   "id": "c8794d8ef71e6223",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "enc_load = torch.load('enc.pth')\n",
    "dec_load = torch.load('dec.pth')"
   ],
   "id": "193931d3151422df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_dataset.data[0].shape",
   "id": "62abbd2bde78dbae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_image_from_dataset(dataset, index=0):\n",
    "    \"\"\"\n",
    "    Affiche une image 28x28 à partir d'un dataset torch.\n",
    "\n",
    "    Paramètres :\n",
    "    - dataset : torch.utils.data.Dataset (par ex. MNIST, FashionMNIST, etc.)\n",
    "    - index : int, l'indice de l'exemple à afficher\n",
    "    \"\"\"\n",
    "    img, label = dataset[index]  # img est un tensor, label est un entier ou un str\n",
    "    if img.ndim == 3:  # (C, H, W)\n",
    "        img = img.squeeze()  # enlève le canal si c'est (1, H, W)\n",
    "\n",
    "    plt.imshow(img.numpy(), cmap='gray')\n",
    "    plt.title(f\"Label : {label}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ],
   "id": "7651db3df5c7e81c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "show_image_from_dataset(train_dataset, 2)",
   "id": "90b4eaf99d791ee6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "dcf8e71ae00f52ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_test = train_dataset.data[2].float().to(device)\n",
    "data_test = data_test.view(1, -1)\n",
    "x = enc.forward(data_test)\n",
    "y = dec(x)\n",
    "# type(y)"
   ],
   "id": "fe099499cc4b8735",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y = y.reshape(28, 28)",
   "id": "3602cfce10db8801",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def show_image_tensor(tensor, title=None):\n",
    "    \"\"\"\n",
    "    Affiche un torch.Tensor représentant une image 28x28 ou 1x28x28.\n",
    "\n",
    "    Paramètres :\n",
    "    - tensor : torch.Tensor (28x28) ou (1x28x28)\n",
    "    - title : str optionnel, titre à afficher\n",
    "    \"\"\"\n",
    "    tensor = tensor.cpu().detach()\n",
    "    if not isinstance(tensor, torch.Tensor):\n",
    "        raise TypeError(\"L'entrée doit être un torch.Tensor.\")\n",
    "\n",
    "    if tensor.ndim == 3 and tensor.shape[0] == 1:\n",
    "        tensor = tensor.squeeze(0)\n",
    "        print(tensor.shape)# (1, 28, 28) → (28, 28)\n",
    "    elif tensor.ndim != 2:\n",
    "        raise ValueError(f\"Tensor de forme invalide : {tensor.shape} (attendu 28x28 ou 1x28x28)\")\n",
    "\n",
    "    print(tensor.shape)\n",
    "    plt.imshow(tensor.numpy(), cmap='gray')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ],
   "id": "604184a08ab74687",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "show_image_tensor(y)",
   "id": "61619ab6d60b1f3b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def show_original_and_reconstructed(dataset, encoder, decoder, n=5, device='cpu'):\n",
    "    \"\"\"\n",
    "    Affiche n paires (original vs reconstruit) à partir d'un dataset et d'un autoencodeur.\n",
    "\n",
    "    Paramètres :\n",
    "    - dataset : torch.utils.data.Dataset\n",
    "    - encoder : nn.Module (entrée flatten 784, sortie latent)\n",
    "    - decoder : nn.Module (entrée latent, sortie flatten 784)\n",
    "    - n : nombre d'exemples à afficher\n",
    "    - device : 'cpu' ou 'cuda'\n",
    "    \"\"\"\n",
    "\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=n, ncols=2, figsize=(4, 2*n))\n",
    "\n",
    "\n",
    "    for i in range(n):\n",
    "        data_test = dataset.data[i].float().to(device)\n",
    "        data_test_flat = data_test.view(1, -1)\n",
    "          # (1, 784)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            z = enc.forward(data_test_flat)\n",
    "            y = dec(z)\n",
    "            recon = y.reshape(28, 28)\n",
    "            # (1, latent_dim)\n",
    "\n",
    "\n",
    "            # Original\n",
    "        axes[i, 0].imshow(data_test.cpu().numpy(), cmap='gray')\n",
    "        axes[i, 0].set_title(\"Original\")\n",
    "        axes[i, 0].axis('off')\n",
    "\n",
    "        # Reconstruit\n",
    "        axes[i, 1].imshow(recon.cpu().numpy(), cmap='gray')\n",
    "        axes[i, 1].set_title(\"Reconstruit\")\n",
    "        axes[i, 1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "        # Rec\n"
   ],
   "id": "7ced86a746029243",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "show_original_and_reconstructed(train_dataset, encoder=enc, decoder=dec, n=10, device=device)",
   "id": "9ff5372f86edf240",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_latent_representations(dataset, encoder, batch_size=128, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Retourne la représentation latente de tout le dataset passé dans l'encodeur.\n",
    "\n",
    "    Paramètres :\n",
    "    - dataset : torch.utils.data.Dataset (ex. MNIST)\n",
    "    - encoder : nn.Module (doit recevoir des tensors 2D [batch_size, 784])\n",
    "    - batch_size : int\n",
    "    - device : 'cpu' ou 'cuda'\n",
    "\n",
    "    Retour :\n",
    "    - latent_vectors : torch.Tensor de forme (N, latent_dim)\n",
    "    - labels : torch.Tensor de forme (N,) si dataset[i] = (image, label)\n",
    "    \"\"\"\n",
    "    encoder.eval()\n",
    "\n",
    "\n",
    "    all_latents = []\n",
    "    all_labels = []\n",
    "    # print(len(dataset))\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        data_test = dataset.data[i].float().to(device)\n",
    "        data_test_flat = data_test.view(1, -1)\n",
    "          # (1, 784)\n",
    "        # print(dataset.targets[i])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            z = enc.forward(data_test_flat)\n",
    "            all_latents.append(z)\n",
    "            all_labels.append(dataset.targets[i].float())\n",
    "\n",
    "\n",
    "    # print(all_labels)\n",
    "    # print(all_latents)\n",
    "    Z = torch.cat(all_latents, dim=0)  # (N, latent_dim)\n",
    "    y = torch.tensor(all_labels) if all_labels else None\n",
    "    # y = all_labels\n",
    "    return Z, y\n"
   ],
   "id": "81f155edf4f49d0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Z, y = get_latent_representations(train_dataset, encoder=enc, batch_size=256, device=device)\n",
   "id": "fdd41a8dbade2b1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import torch\n",
    "\n",
    "def plot_latent_space(Z, y=None, method='pca', n_components=2, title=None):\n",
    "    \"\"\"\n",
    "    Affiche la représentation 2D de l'espace latent Z.\n",
    "\n",
    "    Paramètres :\n",
    "    - Z : torch.Tensor ou np.array de forme (N, D)\n",
    "    - y : torch.Tensor ou array de labels de forme (N,) (optionnel)\n",
    "    - method : 'pca' ou 'tsne'\n",
    "    - n_components : 2 (affichage 2D), ou 3 (3D si tu veux)\n",
    "    - title : titre du graphe\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(Z, torch.Tensor):\n",
    "        Z = Z.cpu().numpy()\n",
    "    if isinstance(y, torch.Tensor):\n",
    "        y = y.cpu().numpy()\n",
    "\n",
    "    if Z.shape[1] > n_components:\n",
    "        if method == 'pca':\n",
    "            reducer = PCA(n_components=n_components)\n",
    "        elif method == 'tsne':\n",
    "            reducer = TSNE(n_components=n_components, init='random', learning_rate='auto')\n",
    "        else:\n",
    "            raise ValueError(\"Méthode inconnue : choisir 'pca' ou 'tsne'\")\n",
    "        Z_proj = reducer.fit_transform(Z)\n",
    "    else:\n",
    "        Z_proj = Z\n",
    "\n",
    "    # Affichage\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    if y is not None:\n",
    "        scatter = plt.scatter(Z_proj[:, 0], Z_proj[:, 1], c=y, cmap='tab10', s=10, alpha=0.7)\n",
    "        plt.legend(*scatter.legend_elements(), title=\"Classe\", loc=\"best\", fontsize='small')\n",
    "    else:\n",
    "        plt.scatter(Z_proj[:, 0], Z_proj[:, 1], s=10, alpha=0.7)\n",
    "\n",
    "    plt.xlabel(\"dim 1\")\n",
    "    plt.ylabel(\"dim 2\")\n",
    "    plt.title(title or f\"Espace latent ({method.upper()})\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "24f44e73da7d1990",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Z.shape",
   "id": "15b70bad8a32ee83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y.shape",
   "id": "1d5f75674f7f563e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_latent_space(Z, y=y, method='pca', title='Latent Space MNIST (PCA)')\n",
   "id": "b97ae998fd1041fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "value_range_x =  [-4000, 3000]\n",
    "value_range_y =  [-7000, 1000]\n",
    "incr = 1000\n",
    "\n",
    "ix = value_range_x[0]\n",
    "iy = value_range_y[0]\n",
    "\n",
    "repr_v = []\n",
    "\n",
    "for i in range(-4000, 3000, 500):\n",
    "    for j in range(-7000, 1000, 500):\n",
    "        repr_v.append([i, j])\n",
    "\n",
    "repr_v_tensor = torch.tensor(repr_v)"
   ],
   "id": "e5c67eb391c146fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "repr_v_tensor.shape",
   "id": "76f7aef096650254",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import math\n",
    "a = math.sqrt(repr_v_tensor.shape[0])\n",
    "a = int(a)\n",
    "print(a)\n",
    "print(a*a)"
   ],
   "id": "b31fda6286aeb1f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def show_decoded_latent_grid(latent_points, decoder, grid_shape=(8, 7), image_shape=(28, 28), device='cpu'):\n",
    "    \"\"\"\n",
    "    Affiche une grille d’images décodées à partir d’un ensemble de points latents.\n",
    "\n",
    "    Paramètres :\n",
    "    - latent_points : (N, latent_dim) — torch.Tensor\n",
    "    - decoder : nn.Module — prend des points de latents en entrée\n",
    "    - grid_shape : tuple (rows, cols)\n",
    "    - image_shape : tuple (H, W)\n",
    "    - device : cpu / cuda\n",
    "    \"\"\"\n",
    "    decoder.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = latent_points.to(device)\n",
    "        decoded = decoder(inputs).cpu()\n",
    "\n",
    "    # reshape les images\n",
    "    decoded = decoded.view(-1, *image_shape)  # (N, H, W)\n",
    "\n",
    "    fig, axes = plt.subplots(*grid_shape, figsize=(grid_shape[1], grid_shape[0]))\n",
    "\n",
    "    for idx, ax in enumerate(axes.flat):\n",
    "        ax.imshow(decoded[idx].numpy(), cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ],
   "id": "927327c7cf48d534",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "repr_v_tensor = torch.tensor(repr_v).float()\n",
    "show_decoded_latent_grid(repr_v_tensor, decoder=dec, grid_shape=(a, a), device=device)"
   ],
   "id": "45295712dd02419",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "878b69c074e997e4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
