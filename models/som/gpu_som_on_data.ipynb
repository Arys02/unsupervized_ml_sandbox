{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-18T08:04:31.580244Z",
     "start_time": "2025-07-18T08:04:30.227644Z"
    }
   },
   "source": "import os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\ndef load_dataset(dataset_path, max_samples_per_class=50):\n    \"\"\"Load dataset with error handling\"\"\"\n    images = []\n    labels = []\n    class_names = []\n\n    if not os.path.exists(dataset_path):\n        return generate_synthetic_data(), [], []\n\n    class_dirs = sorted([d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))])\n\n    for class_idx, class_name in enumerate(class_dirs):\n        class_path = os.path.join(dataset_path, class_name)\n        class_names.append(class_name)\n        \n        image_files = [f for f in os.listdir(class_path) if f.endswith(('.jpg', '.png', '.jpeg'))]\n        loaded_count = 0\n\n        for image_file in image_files:\n            if loaded_count >= max_samples_per_class:\n                break\n                \n            image_path = os.path.join(class_path, image_file)\n            \n            try:\n                if os.path.getsize(image_path) == 0:\n                    continue\n                    \n                img = cv2.imread(image_path)\n                if img is not None:\n                    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                    img_resized = cv2.resize(img_rgb, (64, 64))\n                    images.append(img_resized)\n                    labels.append(class_idx)\n                    loaded_count += 1\n            except:\n                continue\n\n    if len(images) == 0:\n        return generate_synthetic_data()\n    \n    return np.array(images), np.array(labels), class_names\n\ndef generate_synthetic_data():\n    \"\"\"Generate synthetic card data\"\"\"\n    images = []\n    labels = []\n    \n    for card_idx in range(13):\n        for suit_idx in range(4):\n            for variation in range(20):\n                img = np.zeros((64, 64, 3), dtype=np.uint8)\n                \n                base_color = [200, 50, 50] if suit_idx < 2 else [50, 50, 50]\n                \n                if card_idx == 0:\n                    img[25:40, 25:40] = base_color\n                elif card_idx > 9:\n                    img[15:50, 20:45] = base_color\n                    img[20:30, 25:40] = [255, 255, 255]\n                else:\n                    for i in range(min(card_idx + 1, 8)):\n                        y = 10 + (i % 4) * 12\n                        x = 15 + (i // 4) * 25\n                        img[y:y+8, x:x+8] = base_color\n                \n                noise = np.random.normal(0, 15, (64, 64, 3))\n                img = np.clip(img.astype(float) + noise, 0, 255).astype(np.uint8)\n                \n                images.append(img)\n                labels.append(card_idx * 4 + suit_idx)\n    \n    return np.array(images), np.array(labels)\n\n# Load dataset\ndataset_path = '../../data/train_dataset'\ncard_images, card_labels, card_class_names = load_dataset(dataset_path)\n\nif isinstance(card_images, tuple):\n    card_images, card_labels = card_images\n    card_class_names = [f\"synthetic_{i}\" for i in range(len(np.unique(card_labels)))]\n\nprint(f\"Dataset loaded: {card_images.shape[0]} images, {len(np.unique(card_labels))} classes\")\n\n# Display sample images\nfig, axes = plt.subplots(2, 5, figsize=(15, 6))\nfor i, ax in enumerate(axes.flatten()):\n    if i < len(card_images):\n        idx = np.random.randint(0, len(card_images))\n        ax.imshow(card_images[idx])\n        ax.set_title(f'Class {card_labels[idx]}')\n        ax.axis('off')\n\nplt.tight_layout()\nplt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T08:09:48.638021Z",
     "start_time": "2025-07-18T08:09:48.629855Z"
    }
   },
   "cell_type": "code",
   "source": "import torch\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\nclass SOM_GPU:\n    \"\"\"Self-Organizing Map with GPU support\"\"\"\n    def __init__(self, map_size=(10, 10), input_dim=12288, device=None):\n        self.map_height, self.map_width = map_size\n        self.input_dim = input_dim\n        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        \n        self.prototypes = torch.rand(self.map_height, self.map_width, self.input_dim, device=self.device) * 255\n        self.is_trained = False\n        self.training_errors = []\n        \n        print(f\"SOM initialized on {self.device}\")\n    \n    def _find_bmu(self, input_vector):\n        \"\"\"Find Best Matching Unit\"\"\"\n        diffs = self.prototypes - input_vector\n        dists = torch.norm(diffs, dim=2)\n        bmu_index = torch.argmin(dists)\n        return divmod(bmu_index.item(), self.map_width)\n    \n    def _gaussian_neighborhood(self, bmu_pos, sigma):\n        \"\"\"Calculate Gaussian neighborhood\"\"\"\n        bmu_i, bmu_j = bmu_pos\n        i_coords = torch.arange(self.map_height, device=self.device).view(-1, 1)\n        j_coords = torch.arange(self.map_width, device=self.device).view(1, -1)\n        distance_sq = (i_coords - bmu_i)**2 + (j_coords - bmu_j)**2\n        return torch.exp(-distance_sq / (2 * sigma**2))\n    \n    def train(self, training_data, epochs=100, initial_learning_rate=0.1, initial_sigma=3.0):\n        \"\"\"Train the SOM\"\"\"\n        training_data = torch.tensor(training_data, dtype=torch.float32, device=self.device)\n        n_samples = training_data.shape[0]\n        \n        for epoch in tqdm(range(epochs), desc=\"Training SOM\"):\n            progress = epoch / epochs\n            lr = initial_learning_rate * torch.exp(torch.tensor(-5 * progress))\n            sigma = initial_sigma * torch.exp(torch.tensor(-3 * progress))\n            indices = torch.randperm(n_samples)\n            \n            total_error = 0.0\n            for idx in indices:\n                vector = training_data[idx]\n                bmu_pos = self._find_bmu(vector)\n                bmu_i, bmu_j = bmu_pos\n                \n                error = torch.sum((self.prototypes[bmu_i, bmu_j] - vector) ** 2)\n                total_error += error.item()\n                \n                neighborhood = self._gaussian_neighborhood(bmu_pos, sigma)\n                influence = lr * neighborhood.unsqueeze(2)\n                self.prototypes += influence * (vector - self.prototypes)\n            \n            self.training_errors.append(total_error / n_samples)\n        \n        self.is_trained = True\n        print(\"SOM training completed\")\n    \n    def visualize_prototypes(self, image_shape=(64, 64, 3), title=\"SOM Prototypes\"):\n        \"\"\"Visualize SOM prototypes\"\"\"\n        if not self.is_trained:\n            print(\"SOM not trained yet!\")\n            return\n        \n        fig, axes = plt.subplots(self.map_height, self.map_width, figsize=(15, 15))\n        prototypes_cpu = self.prototypes.detach().cpu()\n        \n        for i in range(self.map_height):\n            for j in range(self.map_width):\n                img = prototypes_cpu[i, j].reshape(image_shape)\n                img_normalized = torch.clamp(img, 0, 255).numpy().astype('uint8')\n                axes[i, j].imshow(img_normalized)\n                axes[i, j].axis('off')\n        \n        plt.suptitle(title, fontsize=16)\n        plt.tight_layout()\n        plt.show()\n    \n    def plot_training_progress(self):\n        \"\"\"Plot training error over epochs\"\"\"\n        if not self.training_errors:\n            print(\"No training data available\")\n            return\n        \n        plt.figure(figsize=(10, 6))\n        plt.plot(self.training_errors, 'b-', linewidth=2)\n        plt.title('SOM Training Error')\n        plt.xlabel('Epoch')\n        plt.ylabel('Quantization Error')\n        plt.grid(True, alpha=0.3)\n        plt.show()\n    \n    def compress(self, image):\n        \"\"\"Compress image to BMU coordinates\"\"\"\n        if not self.is_trained:\n            raise ValueError(\"SOM not trained!\")\n        \n        if isinstance(image, np.ndarray) and len(image.shape) >= 2:\n            vector = torch.tensor(image.flatten(), dtype=torch.float32, device=self.device)\n        else:\n            vector = torch.tensor(image, dtype=torch.float32, device=self.device)\n        \n        return self._find_bmu(vector)\n    \n    def decompress(self, compressed_coords):\n        \"\"\"Decompress BMU coordinates back to image\"\"\"\n        if not self.is_trained:\n            raise ValueError(\"SOM not trained!\")\n        \n        bmu_i, bmu_j = compressed_coords\n        return self.prototypes[bmu_i, bmu_j].detach().cpu().numpy().reshape(64, 64, 3)",
   "id": "8ef2e75b9ca4e14c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T08:11:35.698561Z",
     "start_time": "2025-07-18T08:10:10.331521Z"
    }
   },
   "cell_type": "code",
   "source": "# Train SOM and visualize prototypes\nprint(\"Training SOM on card dataset...\")\n\n# Prepare training data\ntraining_images = [img.flatten() for img in card_images[:1000]]\n\n# Create and train SOM\nsom = SOM_GPU(map_size=(10, 10), input_dim=12288)\nsom.train(training_images, epochs=100)\n\n# Visualize results\nsom.visualize_prototypes((64, 64, 3), \"SOM Prototypes - Card Dataset\")\nsom.plot_training_progress()\n\nprint(f\"SOM training completed. Final error: {som.training_errors[-1]:.2f}\")",
   "id": "7e4869047ea2425",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T08:25:58.996285Z",
     "start_time": "2025-07-18T08:18:44.771116Z"
    }
   },
   "cell_type": "code",
   "source": "# Test SOM compression and decompression\nfrom sklearn.metrics import mean_squared_error\n\ndef test_som_compression(som, test_images, test_labels):\n    \"\"\"Test SOM compression and decompression\"\"\"\n    compressed_coords = []\n    reconstructed_images = []\n    \n    for img in test_images:\n        # Compress\n        coords = som.compress(img)\n        compressed_coords.append(coords)\n        \n        # Decompress\n        reconstructed = som.decompress(coords)\n        reconstructed_images.append(reconstructed)\n    \n    return compressed_coords, reconstructed_images\n\ndef visualize_compression_results(original_images, reconstructed_images, compressed_coords, labels):\n    \"\"\"Visualize compression results\"\"\"\n    n_images = len(original_images)\n    fig, axes = plt.subplots(3, n_images, figsize=(18, 9))\n    \n    for i in range(n_images):\n        original = original_images[i]\n        reconstructed = reconstructed_images[i]\n        coords = compressed_coords[i]\n        \n        # Original\n        axes[0, i].imshow(original.astype(np.uint8))\n        axes[0, i].set_title(f'Original\\nLabel: {labels[i]}')\n        axes[0, i].axis('off')\n        \n        # Reconstructed\n        axes[1, i].imshow(reconstructed.astype(np.uint8))\n        axes[1, i].set_title(f'Reconstructed\\nBMU: {coords}')\n        axes[1, i].axis('off')\n        \n        # Error\n        error = np.abs(original.astype(float) - reconstructed.astype(float))\n        axes[2, i].imshow(error.astype(np.uint8))\n        \n        # Calculate MSE\n        mse = mean_squared_error(original.flatten(), reconstructed.flatten())\n        axes[2, i].set_title(f'Error\\nMSE: {mse:.1f}')\n        axes[2, i].axis('off')\n    \n    plt.suptitle('SOM Compression/Decompression Results', fontsize=16)\n    plt.tight_layout()\n    plt.show()\n\n# Test compression\ntest_indices = [0, 100, 200, 300, 400, 500]\ntest_images = [card_images[i] for i in test_indices]\ntest_labels = [card_labels[i] for i in test_indices]\n\ncompressed_coords, reconstructed_images = test_som_compression(som, test_images, test_labels)\n\n# Visualize results\nvisualize_compression_results(test_images, reconstructed_images, compressed_coords, test_labels)\n\n# Calculate compression statistics\ncompression_ratio = 12288 / 2  # 64*64*3 / 2 coordinates\navg_mse = np.mean([mean_squared_error(orig.flatten(), recon.flatten()) \n                   for orig, recon in zip(test_images, reconstructed_images)])\n\nprint(f\"\\nCompression Statistics:\")\nprint(f\"  - Compression ratio: {compression_ratio:.1f}x\")\nprint(f\"  - Average MSE: {avg_mse:.2f}\")\nprint(f\"  - BMU coordinates used: {set(compressed_coords)}\")",
   "id": "fc90491fe5bb6f51",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T08:38:16.602177Z",
     "start_time": "2025-07-18T08:38:16.589803Z"
    }
   },
   "cell_type": "code",
   "source": "# SOM Generator for continuous interpolation\nclass SOM_Generator:\n    \"\"\"Generate images from SOM using interpolation\"\"\"\n    def __init__(self, som):\n        self.som = som\n        if not som.is_trained:\n            raise ValueError(\"SOM must be trained first!\")\n    \n    def _bilinear_interpolation(self, float_i, float_j):\n        \"\"\"Bilinear interpolation between prototypes\"\"\"\n        i_low, i_high = int(np.floor(float_i)), int(np.ceil(float_i))\n        j_low, j_high = int(np.floor(float_j)), int(np.ceil(float_j))\n        \n        # Clamp to valid range\n        i_low = max(0, min(i_low, self.som.map_height - 1))\n        i_high = max(0, min(i_high, self.som.map_height - 1))\n        j_low = max(0, min(j_low, self.som.map_width - 1))\n        j_high = max(0, min(j_high, self.som.map_width - 1))\n        \n        # Interpolation weights\n        w_i = float_i - i_low\n        w_j = float_j - j_low\n        \n        # Get corner prototypes\n        top_left = self.som.prototypes[i_low, j_low]\n        top_right = self.som.prototypes[i_low, j_high]\n        bottom_left = self.som.prototypes[i_high, j_low]\n        bottom_right = self.som.prototypes[i_high, j_high]\n        \n        # Interpolate\n        top = (1 - w_j) * top_left + w_j * top_right\n        bottom = (1 - w_j) * bottom_left + w_j * bottom_right\n        result = (1 - w_i) * top + w_i * bottom\n        \n        return result\n    \n    def generate_from_position(self, position):\n        \"\"\"Generate image from continuous position\"\"\"\n        i, j = position\n        \n        # If integer coordinates, return prototype directly\n        if i == int(i) and j == int(j):\n            return self.som.prototypes[int(i), int(j)].reshape(64, 64, 3).detach().cpu().numpy()\n        \n        # Use interpolation\n        synthetic_vector = self._bilinear_interpolation(i, j)\n        return synthetic_vector.reshape(64, 64, 3).detach().cpu().numpy()\n    \n    def generate_from_latent(self, latent_vector, latent_range=(-1, 1)):\n        \"\"\"Generate image from latent space coordinates\"\"\"\n        x, y = latent_vector\n        latent_min, latent_max = latent_range\n        \n        # Map to SOM coordinates\n        norm_x = (x - latent_min) / (latent_max - latent_min) * (self.som.map_height - 1)\n        norm_y = (y - latent_min) / (latent_max - latent_min) * (self.som.map_width - 1)\n        \n        return self.generate_from_position((norm_x, norm_y))",
   "id": "4e638e933ec9f430",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T08:47:01.487537Z",
     "start_time": "2025-07-18T08:38:47.678073Z"
    }
   },
   "cell_type": "code",
   "source": "# Test SOM generation\ngenerator = SOM_Generator(som)\n\n# Generate images from different latent coordinates\nlatent_vectors = [(-1, -1), (-0.5, 0), (0, 0), (0.5, 0.5), (1, 1)]\n\nfig, axes = plt.subplots(1, len(latent_vectors), figsize=(20, 4))\n\nfor i, latent in enumerate(latent_vectors):\n    image = generator.generate_from_latent(latent)\n    image = np.clip(image, 0, 255).astype(np.uint8)\n    \n    axes[i].imshow(image)\n    axes[i].set_title(f\"Latent: {latent}\")\n    axes[i].axis('off')\n\nplt.suptitle('SOM Generated Images from Latent Space', fontsize=16)\nplt.tight_layout()\nplt.show()\n\n# Generate images from SOM coordinates\nsom_positions = [(0, 0), (2.5, 2.5), (5, 5), (7.5, 7.5), (9, 9)]\n\nfig, axes = plt.subplots(1, len(som_positions), figsize=(20, 4))\n\nfor i, position in enumerate(som_positions):\n    image = generator.generate_from_position(position)\n    image = np.clip(image, 0, 255).astype(np.uint8)\n    \n    axes[i].imshow(image)\n    axes[i].set_title(f\"SOM: {position}\")\n    axes[i].axis('off')\n\nplt.suptitle('SOM Generated Images from Map Coordinates', fontsize=16)\nplt.tight_layout()\nplt.show()",
   "id": "d9d045c491e029a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# End of notebook",
   "id": "ee39747dd103565c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}