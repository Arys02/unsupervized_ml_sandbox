{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-18T05:57:26.979816Z",
     "start_time": "2025-07-18T05:57:20.870898Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "from config import RAW_DATA_DIR"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-07-18 07:57:26.973\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mconfig\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m9\u001B[0m - \u001B[1mPROJ_ROOT path is: /home/arys/projects/unsupervised_ml_experimentation\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T23:04:48.396353Z",
     "start_time": "2025-07-17T23:04:47.393528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_tensor = torch.tensor([3.])\n",
    "\n",
    "w1 = torch.tensor([1.], requires_grad=True)\n",
    "\n",
    "w_mu = torch.tensor([2.], requires_grad=True)\n",
    "w_std = torch.tensor([3.], requires_grad=True)\n",
    "\n",
    "enc_out = input_tensor * w1\n",
    "mu = w_mu * enc_out\n",
    "std = w_std * enc_out\n",
    "#\n",
    "z = mu + std * torch.randn(1)\n",
    "\n",
    "z.backward()\n",
    "# torch.normal(mu, std)"
   ],
   "id": "eaaf7dfbe6339967",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T23:04:54.331787Z",
     "start_time": "2025-07-17T23:04:48.436461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from IPython.display import HTML"
   ],
   "id": "4ad253022871afbf",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T23:36:56.530925Z",
     "start_time": "2025-07-17T23:36:56.284218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "### Prep Dataset ###\n",
    "tensor_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((28, 28)),\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root=RAW_DATA_DIR / 'mnist', train=True, transform=tensor_transforms,\n",
    "                                           download=True)\n",
    "val_dataset = torchvision.datasets.MNIST(root=RAW_DATA_DIR / 'mnist', train=False, transform=tensor_transforms,\n",
    "                                         download=True)\n",
    "batch_size = 1024\n",
    "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=1024, shuffle=True, num_workers=6)\n",
    "val_dl = torch.utils.data.DataLoader(val_dataset, batch_size=1024, shuffle=True, num_workers=6)\n",
    "\n",
    "### Set Device ###\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "id": "4d6e777cc15147cc",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T23:36:59.119340Z",
     "start_time": "2025-07-17T23:36:59.072894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim=2, input_size=28 * 28):\n",
    "        super().__init__()\n",
    "        self.input_size: int = input_size\n",
    "        self.latent_dim: int = latent_dim\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(self.input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "        )\n",
    "        self.fn_mu = nn.Linear(32, self.latent_dim)\n",
    "        self.fn_logvar = nn.Linear(32, self.latent_dim)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, input_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward_dec(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def forward_enc(self, x):\n",
    "\n",
    "        x = self.encoder(x)\n",
    "        mu = self.fn_mu(x)\n",
    "        logvar = self.fn_logvar(x)\n",
    "\n",
    "        sigma = torch.exp(0.5 * logvar)\n",
    "        noise = torch.randn_like(logvar, device=logvar.device)\n",
    "\n",
    "        z = mu + sigma * noise\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, mu, logvar = self.forward_enc(x)\n",
    "\n",
    "        return z, self.decoder(z), mu, logvar\n",
    "\n"
   ],
   "id": "3d5755720d3748eb",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T23:37:00.376027Z",
     "start_time": "2025-07-17T23:37:00.332297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def VAELoss(x, x_hat, mean, log_var, kl_weight=1, reconstruction_weight=1):\n",
    "    pixel_mse = ((x - x_hat)**2)\n",
    "\n",
    "    reconstruction_loss = pixel_mse.sum(axis=-1).mean()\n",
    "    # reconstruction_loss = pixel_mse.mean()\n",
    "\n",
    "\n",
    "    kl = (1 + log_var - mean**2 - torch.exp(log_var))\n",
    "\n",
    "    kl_per_image = -0.5 * torch.sum(kl, dim=-1)\n",
    "\n",
    "\n",
    "    kl_loss = torch.mean(kl_per_image)\n",
    "    #print(reconstruction_loss, kl_loss)\n",
    "\n",
    "    return reconstruction_loss * reconstruction_weight + kl_weight * kl_loss\n",
    "\n",
    "x = torch.randn(4, 128)\n",
    "x_hat = torch.randn(4, 128)\n",
    "\n",
    "mean = torch.randn(4, 2)\n",
    "log_var = torch.randn(4, 2)\n",
    "\n",
    "VAELoss(x, x_hat, mean, log_var)\n"
   ],
   "id": "3f05ed16896e6932",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(289.8410)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Trainning",
   "id": "9160e07a08eed78f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T23:37:01.727991Z",
     "start_time": "2025-07-17T23:37:01.698624Z"
    }
   },
   "cell_type": "code",
   "source": "val_dataset.data.shape[1]",
   "id": "c9272fe57a3c990a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T23:41:31.090758Z",
     "start_time": "2025-07-17T23:37:03.051599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "kl_weight = 1\n",
    "input_size = val_dataset.data.shape[1]**2\n",
    "epochs = 100\n",
    "model = VAE(latent_dim=2, input_size=input_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "val_step = 10\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "train_loss = []\n",
    "\n",
    "encoded_data_per_eval = []\n",
    "train_losses =[]\n",
    "val_losses =[]\n",
    "\n",
    "\n",
    "model.train()\n",
    "\n",
    "train = True\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss_epoch = []\n",
    "\n",
    "    for imgs, _ in train_dl:\n",
    "        imgs = imgs.to(device)\n",
    "        imgs = imgs.flatten(1)\n",
    "\n",
    "        encoded, decoded, mu, logvar = model(imgs)\n",
    "\n",
    "        loss = VAELoss(imgs, decoded, mu, logvar, kl_weight=kl_weight)\n",
    "        train_loss_epoch.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        optimizer.step()\n",
    "    avg_train_loss = np.mean(train_loss_epoch)\n",
    "\n",
    "\n",
    "    if epoch % val_step == 0:\n",
    "        model.eval()\n",
    "        val_loss_epoch = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for img, _ in val_dl:\n",
    "                img = img.to(device)\n",
    "                img = img.flatten(1)\n",
    "                encoded, decoded, mu, logvar = model(img)\n",
    "                loss = VAELoss(img, decoded, mu, logvar, kl_weight=kl_weight)\n",
    "                val_loss_epoch.append(loss.item())\n",
    "\n",
    "        avg_val_loss = np.mean(val_loss_epoch)\n",
    "\n",
    "        print(f\"Epoch {epoch} — train_loss: {avg_train_loss:.6f} — val_loss: {avg_val_loss:.6f}\")\n",
    "                # on sauvegarde les moyennes\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        model.train()\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "8eafe40c4d9258a0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5273a80585724f338610c984618f7661"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 — train_loss: 181.805974 — val_loss: 181.868698\n",
      "Epoch 10 — train_loss: 181.805516 — val_loss: 181.866783\n",
      "Epoch 20 — train_loss: 181.804011 — val_loss: 181.871103\n",
      "Epoch 30 — train_loss: 181.806826 — val_loss: 181.870471\n",
      "Epoch 40 — train_loss: 181.805846 — val_loss: 181.872754\n",
      "Epoch 50 — train_loss: 181.805054 — val_loss: 181.870107\n",
      "Epoch 60 — train_loss: 181.804135 — val_loss: 181.868660\n",
      "Epoch 70 — train_loss: 181.806805 — val_loss: 181.867168\n",
      "Epoch 80 — train_loss: 181.803796 — val_loss: 181.867865\n",
      "Epoch 90 — train_loss: 181.804073 — val_loss: 181.873997\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T23:06:06.856638200Z",
     "start_time": "2025-07-17T16:13:59.437082Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f6d6b6d9f87b5b7b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
       "  )\n",
       "  (fn_mu): Linear(in_features=32, out_features=2, bias=True)\n",
       "  (fn_logvar): Linear(in_features=32, out_features=2, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=784, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6379fc2944263ae3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
